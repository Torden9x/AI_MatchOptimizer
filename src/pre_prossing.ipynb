{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mplsoccer import Pitch\n",
    "import os\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lahd2\\AppData\\Local\\Temp\\ipykernel_14404\\3890916516.py:1: DtypeWarning: Columns (94,95,98,108,111,113,119,120,121,123,124,125,126,127,128,129,130,131,132,133,135,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(r\"C:\\Users\\lahd2\\OneDrive\\Mehdaf\\Ai_comp\\JP1_events.csv\")\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\lahd2\\OneDrive\\Mehdaf\\Ai_comp\\JP1_events.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         index  period     timestamp  minute  second  possession  duration  \\\n",
      "0            1       1  00:00:00.000       0       0           1    0.0000   \n",
      "1            2       1  00:00:00.000       0       0           1    0.0000   \n",
      "2            3       1  00:00:00.000       0       0           1    0.0000   \n",
      "3            4       1  00:00:00.000       0       0           1    0.0000   \n",
      "4            5       1  00:00:00.657       0       0           2    1.2832   \n",
      "...        ...     ...           ...     ...     ...         ...       ...   \n",
      "1244336   3691       2  00:52:37.392      97      37         199    2.4848   \n",
      "1244337   3692       2  00:52:38.733      97      38         199    1.1447   \n",
      "1244338   3693       2  00:52:39.877      97      39         199    0.9747   \n",
      "1244339   3694       2  00:52:40.180      97      40         199    0.0000   \n",
      "1244340   3695       2  00:52:40.180      97      40         199    0.0000   \n",
      "\n",
      "         type_id    type_name  possession_team_id  ...     y  end_x end_y  \\\n",
      "0             35  Starting XI                1881  ...   NaN    NaN   NaN   \n",
      "1             35  Starting XI                1881  ...   NaN    NaN   NaN   \n",
      "2             18   Half Start                1881  ...   NaN    NaN   NaN   \n",
      "3             18   Half Start                1881  ...   NaN    NaN   NaN   \n",
      "4             30         Pass                4609  ...  40.0   39.5  32.6   \n",
      "...          ...          ...                 ...  ...   ...    ...   ...   \n",
      "1244336       43        Carry                1882  ...  22.6    NaN   NaN   \n",
      "1244337       17     Pressure                1882  ...  55.5    NaN   NaN   \n",
      "1244338       30         Pass                1882  ...  25.2   71.9  14.1   \n",
      "1244339       34     Half End                1882  ...   NaN    NaN   NaN   \n",
      "1244340       34     Half End                1882  ...   NaN    NaN   NaN   \n",
      "\n",
      "         carry_end_x carry_end_y  goalkeeper_end_x goalkeeper_end_y  \\\n",
      "0                NaN         NaN               NaN              NaN   \n",
      "1                NaN         NaN               NaN              NaN   \n",
      "2                NaN         NaN               NaN              NaN   \n",
      "3                NaN         NaN               NaN              NaN   \n",
      "4                NaN         NaN               NaN              NaN   \n",
      "...              ...         ...               ...              ...   \n",
      "1244336         74.1        25.2               NaN              NaN   \n",
      "1244337          NaN         NaN               NaN              NaN   \n",
      "1244338          NaN         NaN               NaN              NaN   \n",
      "1244339          NaN         NaN               NaN              NaN   \n",
      "1244340          NaN         NaN               NaN              NaN   \n",
      "\n",
      "        shot_end_x  shot_end_y  shot_end_z  \n",
      "0              NaN         NaN         NaN  \n",
      "1              NaN         NaN         NaN  \n",
      "2              NaN         NaN         NaN  \n",
      "3              NaN         NaN         NaN  \n",
      "4              NaN         NaN         NaN  \n",
      "...            ...         ...         ...  \n",
      "1244336        NaN         NaN         NaN  \n",
      "1244337        NaN         NaN         NaN  \n",
      "1244338        NaN         NaN         NaN  \n",
      "1244339        NaN         NaN         NaN  \n",
      "1244340        NaN         NaN         NaN  \n",
      "\n",
      "[1244341 rows x 166 columns]\n"
     ]
    }
   ],
   "source": [
    "event=df\n",
    "def extract_coordinates(coord_str):\n",
    "    try:\n",
    "        coords = ast.literal_eval(coord_str)\n",
    "        if isinstance(coords, list) and len(coords) == 2:\n",
    "            return coords[0], coords[1]\n",
    "        else:\n",
    "            return None, None\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        return None, None\n",
    "\n",
    "def extract_3d_coordinates(coord_str):\n",
    "    try:\n",
    "        coords = ast.literal_eval(coord_str)\n",
    "        if isinstance(coords, list) and len(coords) == 3:\n",
    "            return coords[0], coords[1], coords[2]\n",
    "        else:\n",
    "            return None, None, None\n",
    "    except (ValueError, SyntaxError, TypeError):\n",
    "        return None, None, None\n",
    "\n",
    "# Extract x, y from location\n",
    "event['x'], event['y'] = zip(*event['location'].apply(extract_coordinates))\n",
    "\n",
    "# Extract end_x, end_y from pass.end_location\n",
    "event['end_x'], event['end_y'] = zip(*event['pass.end_location'].apply(extract_coordinates))\n",
    "\n",
    "# Extract carry_end_x, carry_end_y from carry.end_location\n",
    "event['carry_end_x'], event['carry_end_y'] = zip(*event['carry.end_location'].apply(extract_coordinates))\n",
    "\n",
    "# Extract goalkeeper_end_x, goalkeeper_end_y from goalkeeper.end_location\n",
    "event['goalkeeper_end_x'], event['goalkeeper_end_y'] = zip(*event['goalkeeper.end_location'].apply(extract_coordinates))\n",
    "\n",
    "# Extract shot_end_x, shot_end_y, shot_end_z from shot.end_location\n",
    "event['shot_end_x'], event['shot_end_y'], event['shot_end_z'] = zip(*event['shot.end_location'].apply(extract_3d_coordinates))\n",
    "\n",
    "# Rename dotted column names to underscores\n",
    "event.columns = [col.replace('.', '_') for col in event.columns]\n",
    "\n",
    "# Drop unused original columns\n",
    "event.drop(columns=[\n",
    "    'location', \n",
    "    'pass_end_location', \n",
    "    'carry_end_location',\n",
    "    'goalkeeper_end_location', \n",
    "    'shot_end_location',\n",
    "    'id', \n",
    "    'related_events'\n",
    "], inplace=True, errors='ignore')\n",
    "\n",
    "# Display cleaned DataFrame\n",
    "print(event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lahd2\\AppData\\Local\\Temp\\ipykernel_14404\\3324011044.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  event['pass_outcome_name'].fillna(1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "event['prog_pass'] = np.where((event['type_name'] == 'Pass'), \n",
    "                           np.sqrt((120 - event['x'])**2 + (40 - event['y'])**2) - np.sqrt((120 - event['end_x'])**2 + (40 - event['end_y'])**2), 0)\n",
    "event['prog_carry'] = np.where((event['type_name'] == 'Carry'), \n",
    "                            np.sqrt((120 - event['x'])**2 + (40 - event['y'])**2) - np.sqrt((120 - event['carry_end_x'])**2 + (40 - event['carry_end_y'])**2), 0)\n",
    "event['pass_or_carry_angle'] = np.degrees(np.arctan2(event['end_y'] - event['y'], event['end_x'] - event['x']))\n",
    "event['pass_outcome_name'].fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! All 376 match files saved to: E:\\Ai_com\\match\n"
     ]
    }
   ],
   "source": [
    "events_df = event\n",
    "output_dir = r\"E:\\Ai_com\\match\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "# Group by match_id and save each group to its own CSV file\n",
    "for match_id, match_df in events_df.groupby(\"match_id\"):\n",
    "    match_filename = f\"{output_dir}/match_{str(match_id).zfill(4)}.csv\"\n",
    "    match_df.to_csv(match_filename, index=False)\n",
    "print(f\"✅ Done! All {events_df['match_id'].nunique()} match files saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical = pd.read_csv(r\"C:\\Users\\lahd2\\OneDrive\\Mehdaf\\Ai_comp\\JP1_physical.csv\")\n",
    "player_map = pd.read_csv(r\"C:\\Users\\lahd2\\OneDrive\\Mehdaf\\Ai_comp\\players_mapping.csv\")\n",
    "team_map = pd.read_csv(r\"C:\\Users\\lahd2\\OneDrive\\Mehdaf\\Ai_comp\\teams_mapping.csv\")\n",
    "match_map = pd.read_csv(r\"C:\\Users\\lahd2\\OneDrive\\Mehdaf\\Ai_comp\\matches_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_map.rename(columns={\n",
    "    'wyscout_id': 'player_id_wyscout',\n",
    "    'statsbomb_id': 'playerid'\n",
    "}, inplace=True)\n",
    "\n",
    "team_map.rename(columns={\n",
    "    'wyscout_id': 'team_id_wyscout',\n",
    "    'statsbomb_id': 'teamId'\n",
    "}, inplace=True)\n",
    "\n",
    "match_map.rename(columns={\n",
    "    'wyscout_id': 'match_id_wyscout',\n",
    "    'statsbomb_id': 'matchId'\n",
    "}, inplace=True)\n",
    "physical = pd.merge(physical, player_map, left_on='playerid', right_on='player_id_wyscout', how='left')\n",
    "physical = pd.merge(physical, team_map, left_on='teamId', right_on='team_id_wyscout', how='left')\n",
    "physical = pd.merge(physical, match_map, left_on='matchId', right_on='match_id_wyscout', how='left')\n",
    "physical.drop(columns=[\n",
    "    'player_id_wyscout', 'team_id_wyscout', 'match_id_wyscout'\n",
    "], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   match_id  team_id  player_id                                  label  \\\n",
      "0   3925378     1880    42145.0  Yokohama F. Marinos - Sagan Tosu, 0-1   \n",
      "1   3925378     1880    42145.0  Yokohama F. Marinos - Sagan Tosu, 0-1   \n",
      "2   3925378     1880    42145.0  Yokohama F. Marinos - Sagan Tosu, 0-1   \n",
      "3   3925378     1880    42145.0  Yokohama F. Marinos - Sagan Tosu, 0-1   \n",
      "4   3925378     1880    42145.0  Yokohama F. Marinos - Sagan Tosu, 0-1   \n",
      "\n",
      "               dateutc             teamName    player  \\\n",
      "0  2024-07-03 10:00:00  Yokohama F. Marinos  J. Amano   \n",
      "1  2024-07-03 10:00:00  Yokohama F. Marinos  J. Amano   \n",
      "2  2024-07-03 10:00:00  Yokohama F. Marinos  J. Amano   \n",
      "3  2024-07-03 10:00:00  Yokohama F. Marinos  J. Amano   \n",
      "4  2024-07-03 10:00:00  Yokohama F. Marinos  J. Amano   \n",
      "\n",
      "                      metric     phase  value  \n",
      "0  Count Medium Acceleration   Session  146.0  \n",
      "1  Count Medium Acceleration  1st Half  100.0  \n",
      "2  Count Medium Acceleration  2nd Half   46.0  \n",
      "3  Count Medium Acceleration    1'-15'   30.0  \n",
      "4  Count Medium Acceleration   46'-60'   37.0  \n"
     ]
    }
   ],
   "source": [
    "physical.drop(columns=['matchId_x', 'teamId_x', 'playerid_x'], inplace=True)\n",
    "physical.rename(columns={\n",
    "    'matchId_y': 'match_id',\n",
    "    'teamId_y': 'team_id',\n",
    "    'playerid_y': 'player_id'\n",
    "}, inplace=True)\n",
    "cols = ['match_id', 'team_id', 'player_id'] + [col for col in physical.columns if col not in ['match_id', 'team_id', 'player_id']]\n",
    "physical = physical[cols]\n",
    "print(physical.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enriched: match_3925226.csv\n",
      "✅ Enriched: match_3925227.csv\n",
      "✅ Enriched: match_3925228.csv\n",
      "✅ Enriched: match_3925229.csv\n",
      "✅ Enriched: match_3925230.csv\n",
      "✅ Enriched: match_3925231.csv\n",
      "✅ Enriched: match_3925232.csv\n",
      "✅ Enriched: match_3925233.csv\n",
      "✅ Enriched: match_3925234.csv\n",
      "✅ Enriched: match_3925235.csv\n",
      "✅ Enriched: match_3925236.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lahd2\\AppData\\Local\\Temp\\ipykernel_14404\\1243077751.py:30: DtypeWarning: Columns (16,45,50,56,57,58,77,79,81,85,86,87,88,91,94,96,98,99,101,102,103,105,106,108,110,111,112,116,118,119,120,122,123,125,126,130,131,133,135,140,141,142,144) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  match_df = pd.read_csv(match_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enriched: match_3925237.csv\n",
      "✅ Enriched: match_3925238.csv\n",
      "✅ Enriched: match_3925239.csv\n",
      "✅ Enriched: match_3925240.csv\n",
      "✅ Enriched: match_3925241.csv\n",
      "✅ Enriched: match_3925242.csv\n",
      "✅ Enriched: match_3925243.csv\n",
      "✅ Enriched: match_3925244.csv\n",
      "✅ Enriched: match_3925245.csv\n",
      "✅ Enriched: match_3925246.csv\n",
      "✅ Enriched: match_3925247.csv\n",
      "✅ Enriched: match_3925248.csv\n",
      "✅ Enriched: match_3925249.csv\n",
      "✅ Enriched: match_3925250.csv\n",
      "✅ Enriched: match_3925251.csv\n",
      "✅ Enriched: match_3925252.csv\n",
      "✅ Enriched: match_3925253.csv\n",
      "✅ Enriched: match_3925254.csv\n",
      "✅ Enriched: match_3925255.csv\n",
      "✅ Enriched: match_3925256.csv\n",
      "✅ Enriched: match_3925257.csv\n",
      "✅ Enriched: match_3925258.csv\n",
      "✅ Enriched: match_3925259.csv\n",
      "✅ Enriched: match_3925260.csv\n",
      "✅ Enriched: match_3925261.csv\n",
      "✅ Enriched: match_3925262.csv\n",
      "✅ Enriched: match_3925263.csv\n",
      "✅ Enriched: match_3925264.csv\n",
      "✅ Enriched: match_3925265.csv\n",
      "✅ Enriched: match_3925266.csv\n",
      "✅ Enriched: match_3925267.csv\n",
      "✅ Enriched: match_3925268.csv\n",
      "✅ Enriched: match_3925269.csv\n",
      "✅ Enriched: match_3925270.csv\n",
      "✅ Enriched: match_3925271.csv\n",
      "✅ Enriched: match_3925272.csv\n",
      "✅ Enriched: match_3925273.csv\n",
      "✅ Enriched: match_3925274.csv\n",
      "✅ Enriched: match_3925275.csv\n",
      "✅ Enriched: match_3925276.csv\n",
      "✅ Enriched: match_3925277.csv\n",
      "✅ Enriched: match_3925278.csv\n",
      "✅ Enriched: match_3925279.csv\n",
      "✅ Enriched: match_3925280.csv\n",
      "✅ Enriched: match_3925281.csv\n",
      "✅ Enriched: match_3925282.csv\n",
      "✅ Enriched: match_3925283.csv\n",
      "✅ Enriched: match_3925284.csv\n",
      "✅ Enriched: match_3925285.csv\n",
      "✅ Enriched: match_3925286.csv\n",
      "✅ Enriched: match_3925287.csv\n",
      "✅ Enriched: match_3925288.csv\n",
      "✅ Enriched: match_3925289.csv\n",
      "✅ Enriched: match_3925290.csv\n",
      "✅ Enriched: match_3925291.csv\n",
      "✅ Enriched: match_3925292.csv\n",
      "✅ Enriched: match_3925293.csv\n",
      "✅ Enriched: match_3925294.csv\n",
      "✅ Enriched: match_3925295.csv\n",
      "✅ Enriched: match_3925296.csv\n",
      "✅ Enriched: match_3925297.csv\n",
      "✅ Enriched: match_3925298.csv\n",
      "✅ Enriched: match_3925299.csv\n",
      "✅ Enriched: match_3925300.csv\n",
      "✅ Enriched: match_3925301.csv\n",
      "✅ Enriched: match_3925302.csv\n",
      "✅ Enriched: match_3925303.csv\n",
      "✅ Enriched: match_3925304.csv\n",
      "✅ Enriched: match_3925305.csv\n",
      "✅ Enriched: match_3925306.csv\n",
      "✅ Enriched: match_3925307.csv\n",
      "✅ Enriched: match_3925308.csv\n",
      "✅ Enriched: match_3925309.csv\n",
      "✅ Enriched: match_3925310.csv\n",
      "✅ Enriched: match_3925311.csv\n",
      "✅ Enriched: match_3925312.csv\n",
      "✅ Enriched: match_3925313.csv\n",
      "✅ Enriched: match_3925314.csv\n",
      "✅ Enriched: match_3925315.csv\n",
      "✅ Enriched: match_3925316.csv\n",
      "✅ Enriched: match_3925317.csv\n",
      "✅ Enriched: match_3925318.csv\n",
      "✅ Enriched: match_3925319.csv\n",
      "✅ Enriched: match_3925320.csv\n",
      "✅ Enriched: match_3925321.csv\n",
      "✅ Enriched: match_3925322.csv\n",
      "✅ Enriched: match_3925323.csv\n",
      "✅ Enriched: match_3925324.csv\n",
      "✅ Enriched: match_3925325.csv\n",
      "✅ Enriched: match_3925326.csv\n",
      "✅ Enriched: match_3925327.csv\n",
      "✅ Enriched: match_3925328.csv\n",
      "✅ Enriched: match_3925329.csv\n",
      "✅ Enriched: match_3925330.csv\n",
      "✅ Enriched: match_3925331.csv\n",
      "✅ Enriched: match_3925332.csv\n",
      "✅ Enriched: match_3925333.csv\n",
      "✅ Enriched: match_3925334.csv\n",
      "✅ Enriched: match_3925335.csv\n",
      "✅ Enriched: match_3925336.csv\n",
      "✅ Enriched: match_3925337.csv\n",
      "✅ Enriched: match_3925338.csv\n",
      "✅ Enriched: match_3925339.csv\n",
      "✅ Enriched: match_3925340.csv\n",
      "✅ Enriched: match_3925341.csv\n",
      "✅ Enriched: match_3925342.csv\n",
      "✅ Enriched: match_3925343.csv\n",
      "✅ Enriched: match_3925344.csv\n",
      "✅ Enriched: match_3925345.csv\n",
      "✅ Enriched: match_3925346.csv\n",
      "✅ Enriched: match_3925347.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lahd2\\AppData\\Local\\Temp\\ipykernel_14404\\1243077751.py:30: DtypeWarning: Columns (16,17,45,49,53,55,56,57,64,66,68,70,72,74,75,77,79,81,83,84,85,86,87,88,90,91,94,96,98,99,101,102,103,104,106,108,110,111,116,117,118,119,120,121,122,123,124,125,131,134,136,137,138,139,141,142,143) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  match_df = pd.read_csv(match_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enriched: match_3925348.csv\n",
      "✅ Enriched: match_3925349.csv\n",
      "✅ Enriched: match_3925350.csv\n",
      "✅ Enriched: match_3925351.csv\n",
      "✅ Enriched: match_3925352.csv\n",
      "✅ Enriched: match_3925353.csv\n",
      "✅ Enriched: match_3925354.csv\n",
      "✅ Enriched: match_3925355.csv\n",
      "✅ Enriched: match_3925356.csv\n",
      "✅ Enriched: match_3925357.csv\n",
      "✅ Enriched: match_3925358.csv\n",
      "✅ Enriched: match_3925359.csv\n",
      "✅ Enriched: match_3925360.csv\n",
      "✅ Enriched: match_3925361.csv\n",
      "✅ Enriched: match_3925362.csv\n",
      "✅ Enriched: match_3925363.csv\n",
      "✅ Enriched: match_3925364.csv\n",
      "✅ Enriched: match_3925365.csv\n",
      "✅ Enriched: match_3925366.csv\n",
      "✅ Enriched: match_3925367.csv\n",
      "✅ Enriched: match_3925368.csv\n",
      "✅ Enriched: match_3925369.csv\n",
      "✅ Enriched: match_3925370.csv\n",
      "✅ Enriched: match_3925371.csv\n",
      "✅ Enriched: match_3925372.csv\n",
      "✅ Enriched: match_3925373.csv\n",
      "✅ Enriched: match_3925374.csv\n",
      "✅ Enriched: match_3925375.csv\n",
      "✅ Enriched: match_3925376.csv\n",
      "✅ Enriched: match_3925377.csv\n",
      "✅ Enriched: match_3925378.csv\n",
      "✅ Enriched: match_3925379.csv\n",
      "✅ Enriched: match_3925380.csv\n",
      "✅ Enriched: match_3925381.csv\n",
      "✅ Enriched: match_3925382.csv\n",
      "✅ Enriched: match_3925383.csv\n",
      "✅ Enriched: match_3925384.csv\n",
      "✅ Enriched: match_3925385.csv\n",
      "✅ Enriched: match_3925386.csv\n",
      "✅ Enriched: match_3925387.csv\n",
      "✅ Enriched: match_3925388.csv\n",
      "✅ Enriched: match_3925389.csv\n",
      "✅ Enriched: match_3925390.csv\n",
      "✅ Enriched: match_3925391.csv\n",
      "✅ Enriched: match_3925392.csv\n",
      "✅ Enriched: match_3925393.csv\n",
      "✅ Enriched: match_3925394.csv\n",
      "✅ Enriched: match_3925395.csv\n",
      "✅ Enriched: match_3925396.csv\n",
      "✅ Enriched: match_3925397.csv\n",
      "✅ Enriched: match_3925398.csv\n",
      "✅ Enriched: match_3925399.csv\n",
      "✅ Enriched: match_3925400.csv\n",
      "✅ Enriched: match_3925401.csv\n",
      "✅ Enriched: match_3925402.csv\n",
      "✅ Enriched: match_3925403.csv\n",
      "✅ Enriched: match_3925404.csv\n",
      "✅ Enriched: match_3925405.csv\n",
      "✅ Enriched: match_3925406.csv\n",
      "✅ Enriched: match_3925407.csv\n",
      "✅ Enriched: match_3925408.csv\n",
      "✅ Enriched: match_3925409.csv\n",
      "✅ Enriched: match_3925410.csv\n",
      "✅ Enriched: match_3925411.csv\n",
      "✅ Enriched: match_3925412.csv\n",
      "✅ Enriched: match_3925413.csv\n",
      "✅ Enriched: match_3925414.csv\n",
      "✅ Enriched: match_3925415.csv\n",
      "✅ Enriched: match_3925416.csv\n",
      "✅ Enriched: match_3925417.csv\n",
      "✅ Enriched: match_3925418.csv\n",
      "✅ Enriched: match_3925419.csv\n",
      "✅ Enriched: match_3925420.csv\n",
      "✅ Enriched: match_3925421.csv\n",
      "✅ Enriched: match_3925422.csv\n",
      "✅ Enriched: match_3925423.csv\n",
      "✅ Enriched: match_3925424.csv\n",
      "✅ Enriched: match_3925425.csv\n",
      "✅ Enriched: match_3925426.csv\n",
      "✅ Enriched: match_3925427.csv\n",
      "✅ Enriched: match_3925428.csv\n",
      "✅ Enriched: match_3925429.csv\n",
      "✅ Enriched: match_3925430.csv\n",
      "✅ Enriched: match_3925431.csv\n",
      "✅ Enriched: match_3925432.csv\n",
      "✅ Enriched: match_3925433.csv\n",
      "✅ Enriched: match_3925434.csv\n",
      "✅ Enriched: match_3925435.csv\n",
      "✅ Enriched: match_3925436.csv\n",
      "✅ Enriched: match_3925437.csv\n",
      "✅ Enriched: match_3925438.csv\n",
      "✅ Enriched: match_3925439.csv\n",
      "✅ Enriched: match_3925440.csv\n",
      "✅ Enriched: match_3925441.csv\n",
      "✅ Enriched: match_3925442.csv\n",
      "✅ Enriched: match_3925443.csv\n",
      "✅ Enriched: match_3925444.csv\n",
      "✅ Enriched: match_3925445.csv\n",
      "✅ Enriched: match_3925446.csv\n",
      "✅ Enriched: match_3925447.csv\n",
      "✅ Enriched: match_3925448.csv\n",
      "✅ Enriched: match_3925449.csv\n",
      "✅ Enriched: match_3925450.csv\n",
      "✅ Enriched: match_3925451.csv\n",
      "✅ Enriched: match_3925452.csv\n",
      "✅ Enriched: match_3925453.csv\n",
      "✅ Enriched: match_3925454.csv\n",
      "✅ Enriched: match_3925455.csv\n",
      "✅ Enriched: match_3925456.csv\n",
      "✅ Enriched: match_3925457.csv\n",
      "✅ Enriched: match_3925458.csv\n",
      "✅ Enriched: match_3925459.csv\n",
      "✅ Enriched: match_3925460.csv\n",
      "✅ Enriched: match_3925461.csv\n",
      "✅ Enriched: match_3925462.csv\n",
      "✅ Enriched: match_3925463.csv\n",
      "✅ Enriched: match_3925464.csv\n",
      "✅ Enriched: match_3925465.csv\n",
      "✅ Enriched: match_3925466.csv\n",
      "✅ Enriched: match_3925467.csv\n",
      "✅ Enriched: match_3925468.csv\n",
      "✅ Enriched: match_3925469.csv\n",
      "✅ Enriched: match_3925470.csv\n",
      "✅ Enriched: match_3925471.csv\n",
      "✅ Enriched: match_3925472.csv\n",
      "✅ Enriched: match_3925473.csv\n",
      "✅ Enriched: match_3925474.csv\n",
      "✅ Enriched: match_3925475.csv\n",
      "✅ Enriched: match_3925476.csv\n",
      "✅ Enriched: match_3925477.csv\n",
      "✅ Enriched: match_3925478.csv\n",
      "✅ Enriched: match_3925479.csv\n",
      "✅ Enriched: match_3925480.csv\n",
      "✅ Enriched: match_3925481.csv\n",
      "✅ Enriched: match_3925482.csv\n",
      "✅ Enriched: match_3925483.csv\n",
      "✅ Enriched: match_3925484.csv\n",
      "✅ Enriched: match_3925485.csv\n",
      "✅ Enriched: match_3925486.csv\n",
      "✅ Enriched: match_3925487.csv\n",
      "✅ Enriched: match_3925488.csv\n",
      "✅ Enriched: match_3925489.csv\n",
      "✅ Enriched: match_3925490.csv\n",
      "✅ Enriched: match_3925491.csv\n",
      "✅ Enriched: match_3925492.csv\n",
      "✅ Enriched: match_3925493.csv\n",
      "✅ Enriched: match_3925494.csv\n",
      "✅ Enriched: match_3925495.csv\n",
      "✅ Enriched: match_3925496.csv\n",
      "✅ Enriched: match_3925497.csv\n",
      "✅ Enriched: match_3925498.csv\n",
      "✅ Enriched: match_3925499.csv\n",
      "✅ Enriched: match_3925500.csv\n",
      "✅ Enriched: match_3925501.csv\n",
      "✅ Enriched: match_3925502.csv\n",
      "✅ Enriched: match_3925503.csv\n",
      "✅ Enriched: match_3925504.csv\n",
      "✅ Enriched: match_3925505.csv\n",
      "✅ Enriched: match_3925506.csv\n",
      "✅ Enriched: match_3925507.csv\n",
      "✅ Enriched: match_3925508.csv\n",
      "✅ Enriched: match_3925509.csv\n",
      "✅ Enriched: match_3925510.csv\n",
      "✅ Enriched: match_3925511.csv\n",
      "✅ Enriched: match_3925512.csv\n",
      "✅ Enriched: match_3925513.csv\n",
      "✅ Enriched: match_3925514.csv\n",
      "✅ Enriched: match_3925515.csv\n",
      "✅ Enriched: match_3925516.csv\n",
      "✅ Enriched: match_3925517.csv\n",
      "✅ Enriched: match_3925518.csv\n",
      "✅ Enriched: match_3925519.csv\n",
      "✅ Enriched: match_3925520.csv\n",
      "✅ Enriched: match_3925521.csv\n",
      "✅ Enriched: match_3925522.csv\n",
      "✅ Enriched: match_3925523.csv\n",
      "✅ Enriched: match_3925524.csv\n",
      "✅ Enriched: match_3925525.csv\n",
      "✅ Enriched: match_3925526.csv\n",
      "✅ Enriched: match_3925527.csv\n",
      "✅ Enriched: match_3925528.csv\n",
      "✅ Enriched: match_3925529.csv\n",
      "✅ Enriched: match_3925530.csv\n",
      "✅ Enriched: match_3925531.csv\n",
      "✅ Enriched: match_3925532.csv\n",
      "✅ Enriched: match_3925533.csv\n",
      "✅ Enriched: match_3925534.csv\n",
      "✅ Enriched: match_3925535.csv\n",
      "✅ Enriched: match_3925536.csv\n",
      "✅ Enriched: match_3925537.csv\n",
      "✅ Enriched: match_3925538.csv\n",
      "✅ Enriched: match_3925539.csv\n",
      "✅ Enriched: match_3925540.csv\n",
      "✅ Enriched: match_3925541.csv\n",
      "✅ Enriched: match_3925542.csv\n",
      "✅ Enriched: match_3925543.csv\n",
      "✅ Enriched: match_3925544.csv\n",
      "✅ Enriched: match_3925545.csv\n",
      "✅ Enriched: match_3925546.csv\n",
      "✅ Enriched: match_3925547.csv\n",
      "✅ Enriched: match_3925548.csv\n",
      "✅ Enriched: match_3925549.csv\n",
      "✅ Enriched: match_3925550.csv\n",
      "✅ Enriched: match_3925551.csv\n",
      "✅ Enriched: match_3925552.csv\n",
      "✅ Enriched: match_3925553.csv\n",
      "✅ Enriched: match_3925554.csv\n",
      "✅ Enriched: match_3925555.csv\n",
      "✅ Enriched: match_3925556.csv\n",
      "✅ Enriched: match_3925557.csv\n",
      "✅ Enriched: match_3925558.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lahd2\\AppData\\Local\\Temp\\ipykernel_14404\\1243077751.py:30: DtypeWarning: Columns (16,17,50,64,66,68,70,72,74,77,79,81,84,86,88,91,94,96,99,101,103,106,112,116,117,118,119,120,122,123,124,125,130,131,134,135,138,139) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  match_df = pd.read_csv(match_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enriched: match_3925559.csv\n",
      "✅ Enriched: match_3925560.csv\n",
      "✅ Enriched: match_3925561.csv\n",
      "✅ Enriched: match_3925562.csv\n",
      "✅ Enriched: match_3925563.csv\n",
      "✅ Enriched: match_3925564.csv\n",
      "✅ Enriched: match_3925565.csv\n",
      "✅ Enriched: match_3925566.csv\n",
      "✅ Enriched: match_3925567.csv\n",
      "✅ Enriched: match_3925568.csv\n",
      "✅ Enriched: match_3925569.csv\n",
      "✅ Enriched: match_3925570.csv\n",
      "✅ Enriched: match_3925571.csv\n",
      "✅ Enriched: match_3925572.csv\n",
      "✅ Enriched: match_3925573.csv\n",
      "✅ Enriched: match_3925574.csv\n",
      "✅ Enriched: match_3925575.csv\n",
      "✅ Enriched: match_3925576.csv\n",
      "✅ Enriched: match_3925577.csv\n",
      "✅ Enriched: match_3925578.csv\n",
      "✅ Enriched: match_3925579.csv\n",
      "✅ Enriched: match_3925580.csv\n",
      "✅ Enriched: match_3925581.csv\n",
      "✅ Enriched: match_3925582.csv\n",
      "✅ Enriched: match_3925583.csv\n",
      "✅ Enriched: match_3925584.csv\n",
      "✅ Enriched: match_3925585.csv\n",
      "✅ Enriched: match_3925586.csv\n",
      "✅ Enriched: match_3925587.csv\n",
      "✅ Enriched: match_3925588.csv\n",
      "✅ Enriched: match_3925589.csv\n",
      "✅ Enriched: match_3925590.csv\n",
      "✅ Enriched: match_3925591.csv\n",
      "✅ Enriched: match_3925592.csv\n",
      "✅ Enriched: match_3925593.csv\n",
      "✅ Enriched: match_3925594.csv\n",
      "✅ Enriched: match_3925595.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lahd2\\AppData\\Local\\Temp\\ipykernel_14404\\1243077751.py:30: DtypeWarning: Columns (16,50,52,53,55,75,77,79,83,90,91,96,98,99,101,102,104,106,108,110,111,112,116,118,119,120,122,124,125,130,131,132,133) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  match_df = pd.read_csv(match_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Enriched: match_3925597.csv\n",
      "✅ Enriched: match_3925598.csv\n",
      "✅ Enriched: match_3925600.csv\n",
      "✅ Enriched: match_3925601.csv\n",
      "✅ Enriched: match_3925602.csv\n",
      "✅ Enriched: match_3925603.csv\n"
     ]
    }
   ],
   "source": [
    "phase_time_ranges = {\n",
    "    \"1'-15'\": (1, 15),\n",
    "    \"16'-30'\": (16, 30),\n",
    "    \"31'-45+'\": (31, 45),\n",
    "    \"46'-60'\": (46, 60),\n",
    "    \"61'-75'\": (61, 75),\n",
    "    \"76'-120+'\": (76, 120)\n",
    "}\n",
    "target_metrics = [\n",
    "    'Count Medium Acceleration', 'Count High Acceleration',\n",
    "    'Count Medium Deceleration', 'Count High Deceleration',\n",
    "    'Total Distance', 'M/min', 'Running Distance',\n",
    "    'High Speed Running (HSR) Distance', 'Sprinting Distance',\n",
    "    'High Intensity (HI) Distance', 'Count HSR', 'Count Sprint',\n",
    "    'Count HI', 'Max Speed'\n",
    "]\n",
    "phys_pivot = physical.pivot_table(\n",
    "    index=['match_id', 'team_id', 'player_id', 'phase'],\n",
    "    columns='metric',\n",
    "    values='value'\n",
    ").reset_index()\n",
    "phys_pivot.columns.name = None\n",
    "phys_pivot.rename(columns=lambda x: x.strip().lower().replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\"), inplace=True)\n",
    "match_folder = r\"E:\\Ai_com\\match\"\n",
    "output_folder = r\"E:\\Ai_com\\match_enriched\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "for file in os.listdir(match_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        match_path = os.path.join(match_folder, file)\n",
    "        match_df = pd.read_csv(match_path)\n",
    "\n",
    "        match_id = int(file.split(\"_\")[1].split(\".\")[0])\n",
    "        match_phys = phys_pivot[phys_pivot['match_id'] == match_id]\n",
    "\n",
    "        enriched_rows = []\n",
    "\n",
    "        for _, row in match_df.iterrows():\n",
    "            minute = row.get('minute')\n",
    "            if pd.isna(minute):\n",
    "                enriched_rows.append(row.to_dict())\n",
    "                continue\n",
    "\n",
    "            # Determine the phase\n",
    "            matching_phase = None\n",
    "            for phase, (start, end) in phase_time_ranges.items():\n",
    "                if start <= minute <= end:\n",
    "                    matching_phase = phase\n",
    "                    break\n",
    "\n",
    "            if not matching_phase:\n",
    "                enriched_rows.append(row.to_dict())\n",
    "                continue\n",
    "\n",
    "            # Find matching physical data\n",
    "            match_phys_row = match_phys[\n",
    "                (match_phys['team_id'] == row['team_id']) &\n",
    "                (match_phys['player_id'] == row['player_id']) &\n",
    "                (match_phys['phase'] == matching_phase)\n",
    "            ]\n",
    "\n",
    "            row_dict = row.to_dict()\n",
    "\n",
    "            if not match_phys_row.empty:\n",
    "                phys_values = match_phys_row.iloc[0].to_dict()\n",
    "                row_dict.update(phys_values)\n",
    "\n",
    "            enriched_rows.append(row_dict)\n",
    "\n",
    "        enriched_df = pd.DataFrame(enriched_rows)\n",
    "        enriched_df.to_csv(os.path.join(output_folder, file), index=False)\n",
    "        print(f\"✅ Enriched: {file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
